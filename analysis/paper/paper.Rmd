---
title: "Title Goes Here"
author:
  - author 1
  - author 2
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
    bookdown::html_document2:
    fig_caption: yes
    reference_docx: templates/template.docx
bibliography: references.bib
csl: journal-of-archaeological-science.csl
abstract: |
  Text of abstract
keywords: |
  keyword 1; keyword 2; keyword 3
highlights: |
  These are the highlights. 
---


<!-- This is the format for text comments that will be ignored during renderings. Do not put R code in these comments because it will not be ignored. -->

```{r, setup, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  eval = FALSE,
  comment = "#>",
  fig.path = "../figures/"
)

library(datacitation)

# my custom plot theme
theme_new <- function(base_size = 12){
  theme_bw(base_size = base_size) %+replace%
    theme(
      #axis.title.x=element_blank(),
      # axis.title.y=element_blank(),
      axis.title = element_text(size = 14),
      legend.key=element_rect(colour=NA, fill =NA),
      # panel.grid = element_blank(),   
      panel.border = element_rect(fill = NA, colour = "black", size=0.5),
      panel.background = element_rect(fill = "white", colour = "black"), 
      strip.background = element_rect(fill = NA)
    )
}

```

# Email survey of data sharing behaviours

```{r eval = TRUE}
library(tidyverse)
email_survey <- readr::read_csv("../data/raw_data/email_survey.csv")

# overall rate of response
emails_out <- sum(!is.na(email_survey$`email sent date`))
emails_back <- sum(!is.na(email_survey$`response received date`))
email_response_rate <- round(emails_back / emails_out, 1) * 100
data_items_received <-  sum(!is.na(email_survey$`content recieved date`))
sharing_rate <-  round(data_items_received / emails_out, 1) * 100
```

We conducted a small pilot study to explore data sharing in archaeology. Our sample focused on _Journal of Archaeological Science_ articles on experiments with stone artefacts that were published during `r min(email_survey$'publication year', na.rm = TRUE)` and `r max(email_survey$'publication year', na.rm = TRUE)`. We focused on stone artefact experiments because the all research materials are generated by the researcher so there are not other stakeholders to consider when determining how to share the data: the researcher has complete control over the data. There are also no risks of damage to people or property in sharing these data because they do not include archaeological sites or human subjects. In contacting the authors, we requested the datasets for use in a graduate seminar with the aim of reproducing the published results and further exploring the data (this stage is still in progress). We promised to contact the authors if we discovered anything new, and not to share the data further without their permission. The data included with this paper is anonymised so the specific authors we contacted cannot be identified. 

We sent out `r emails_out` emails to authors of these papers, and received `r emails_back`, resulting in a `r email_response_rate`% response rate. We recieved `r data_items_received` responses that included data files, giving an overall sharing rate of `r sharing_rate`%. Our small sample size limits the robustness of our analysis, but points to some observations that may be worth following up in a larger study. We found no clear relationship of data sharing and date of publication. We do not have any insights into why authors of older papers decline to share, but three of the six responses for papers published in 2014-2015 said they declined to share data because they intend to use these data in a future publication. Other noteworthy reasons provided by respondents for delining to share include the author about to defend their thesis or about to go on vacation. We interpret these to mean that the author does not have time to prepare their data for sharing, perhaps because the data are not already in a well-organised for ready for distribution. We found no effect on the author's student status at time of publication on data sharing behaviours, with roughly equal proportions of students and non-students sharing and not sharing. Similarly there are no clear patterns data sharing of among different journals. It is remarkable that the authors of the one PLOS One paper we contacted declined to share because that violates the policy of that journal at the time of publication of that paper (early 2014): "Publication is conditional upon the agreement of the authors to make freely available any materials and information described in their publication that may be reasonably requested by others for the purpose of academic, non-commercial research."  

```{r date-and-sharing, fig.cap="There is no obvious trend in data sharing becavious and date of publication", eval = TRUE}
library(viridis)
years <- seq(min(email_survey$'publication year', na.rm = TRUE),
    max(email_survey$'publication year', na.rm = TRUE), 1)
email_survey %>% 
  filter(!is.na( `email sent date`)) %>% 
  group_by(`publication year`, `content recieved date`) %>% 
  tally() %>% 
  filter(!is.na(`publication year`)) %>% 
  mutate(`content recieved date` = if_else(!is.na(`content recieved date`), 
  "yes", "no")) %>% 
  ggplot(aes(`publication year`, n)) +
    geom_col(aes(fill = `content recieved date`),
             position = position_dodge(preserve = 'single')) +
    scale_fill_viridis(discrete = TRUE,
                       guide = guide_legend(title = "Data shared?")) +
    scale_x_continuous(breaks = years,
                       labels = years) +
    theme_bw()

```

```{r student, fig.cap="No relationship between student status and data sharing behaviour", eval = TRUE}
email_survey %>% 
  filter(!is.na( `email sent date`)) %>% 
    mutate(`content recieved date` = if_else(!is.na(`content recieved date`), 
  "yes", "no")) %>% 
  group_by(
  `author is graduate student at time of publication?`, 
  `content recieved date`) %>% 
  tally() %>% 
  filter(!is.na(`author is graduate student at time of publication?`)) %>% 
  ggplot(aes(`author is graduate student at time of publication?`, n)) +
    geom_col(aes(fill = `content recieved date`),
             position = position_dodge(preserve = 'single')) +
    scale_fill_viridis(discrete = TRUE,
                       guide = guide_legend(title = "Data shared?")) +
    theme_bw()
```

```{r author-country, eval = TRUE}
email_survey %>% 
  filter(!is.na( `email sent date`)) %>% 
    mutate(`content recieved date` = if_else(!is.na(`content recieved date`), 
  "yes", "no")) %>% 
  group_by(
  `author home`, 
  `content recieved date`) %>% 
  tally() %>% 
  filter(!is.na(`author home`)) %>% 
  ggplot(aes(`author home`, n)) +
    geom_col(aes(fill = `content recieved date`),
             position = position_dodge(preserve = 'single')) +
    scale_fill_viridis(discrete = TRUE,
                       guide = guide_legend(title = "Data shared?")) +
    theme_bw()
```


```{r journals, fig.cap="No relationship between sharing behaviour and journal.", eval = TRUE}
email_survey %>% 
  filter(!is.na( `email sent date`)) %>% 
    mutate(`content recieved date` = if_else(!is.na(`content recieved date`), 
  "yes", "no")) %>% 
  group_by(
  journal, 
  `content recieved date`) %>% 
  tally() %>% 
  filter(!is.na(journal)) %>% 
  ggplot(aes(journal, n)) +
    geom_col(aes(fill = `content recieved date`),
             position = position_dodge(preserve = 'single')) +
    scale_fill_viridis(discrete = TRUE,
                       guide = guide_legend(title = "Data shared?")) +
    theme_bw()
```

# Survey of articles published in JAS

```{r eval = TRUE}
jas_article_survey <- readr::read_csv("../data/raw_data/jas_article_survey.csv")

have_data_avail_statement <- nrow(jas_article_survey[jas_article_survey$`Data availability statement` != "none", ])
have_data_avail_statement_perc <- round(have_data_avail_statement / nrow(jas_article_survey) * 100,0)
data_are_avail <- nrow(jas_article_survey[jas_article_survey$`Can I access the data without contacting the authors?` %in% c("Yes", "yes"), ])
data_are_avail_perc <- round(data_are_avail / nrow(jas_article_survey) * 100,0)

data_in_table <-  nrow(jas_article_survey[grepl("Tab", jas_article_survey$`Where is the data?`), ])
data_in_table_perc <- round(data_in_table / data_are_avail * 100, 0)

data_in_supp <-  nrow(jas_article_survey[grepl("Sup", jas_article_survey$`Where is the data?`), ])
data_in_supp_perc <- round(data_in_supp / data_are_avail * 100, 0)

data_in_repo <-  nrow(jas_article_survey[grepl("www|dryad|osf", tolower(jas_article_survey$`Where is the data?`)), ])
data_in_repo_perc <- round(data_in_repo / data_are_avail * 100, 0)

data_type <- jas_article_survey %>% 
  filter(`data type?` != "na") %>% 
  group_by(`data type?`) %>% 
  tally(sort = TRUE) %>% 
  mutate(perc = round(n / sum(n) *100,1))

comp_n <- data_type %>% 
  filter(`data type?`  == "compositional") %>% 
  pull(n)

comp_perc <- data_type %>% 
  filter(`data type?`  == "compositional") %>% 
  pull(perc)

dna_n <- data_type %>% 
  filter(`data type?`  == "DNA sequence") %>% 
  pull(n)

dna_perc <- data_type %>% 
  filter(`data type?`  == "DNA sequence") %>% 
  pull(perc)

dates_n <- data_type %>% 
  filter(grepl("dates", `data type?`)) %>% 
  summarise(n = sum(n)) %>% 
  pull(n)

dates_perc <- data_type %>% 
  filter(grepl("dates", `data type?`)) %>% 
  summarise(n = sum(n),
            perc = sum(perc)) %>% 
  pull(perc)

file_type <- jas_article_survey %>% 
  filter(`What file format?` != "na") %>% 
  group_by(`What file format?`) %>% 
  tally(sort = TRUE) %>% 
  mutate(perc = round(n / sum(n) *100,1))

xlsx_n <- file_type %>% 
  filter(grepl("XLSX", `What file format?`)) %>% 
  summarise(n = sum(n),
            perc = sum(perc)) %>% 
  pull(n)

xlsx_perc <- file_type %>% 
  filter(grepl("XLSX", `What file format?`)) %>% 
  summarise(n = sum(n),
            perc = sum(perc)) %>% 
  pull(perc)

csv_n <- file_type %>% 
  filter(grepl("CSV", `What file format?`)) %>% 
  summarise(n = sum(n),
            perc = sum(perc)) %>% 
  pull(n)

csv_perc <- file_type %>% 
  filter(grepl("CSV", `What file format?`)) %>% 
  summarise(n = sum(n),
            perc = sum(perc)) %>% 
  pull(perc)

doc_n <- file_type %>% 
  filter(grepl("doc|DOC", `What file format?`)) %>% 
  summarise(n = sum(n),
            perc = sum(perc)) %>% 
  pull(n)

doc_perc <- file_type %>% 
  filter(grepl("doc|DOC", `What file format?`)) %>% 
  summarise(n = sum(n),
            perc = sum(perc)) %>% 
  pull(perc)

software <- jas_article_survey %>% 
  filter(`Analysis software?` != "na") %>% 
  group_by(`Analysis software?`) %>% 
  tally(sort = TRUE) %>% 
  mutate(perc = round(n / sum(n) *100,1))

script_n <- software %>% 
  filter(grepl("^R$|.*R$|Python|MATLAB|OxCal", `Analysis software?`)) %>% 
  summarise(n = sum(n),
            perc = sum(perc)) %>% 
  pull(n)

script_perc <- software %>% 
  filter(grepl("^R$|.*R$|Python|MATLAB|OxCal", `Analysis software?`)) %>% 
  summarise(n = sum(n),
            perc = sum(perc)) %>% 
  pull(perc)

```

In addition to our email survey, we also conducted a pilot study of a random sample of `r nrow(jas_article_survey)` articles published during 2016-2017 in the _Journal of Archaeological Science_ to investigate data sharing behaviours. In this sample we found openly available raw data in `r data_are_avail` papers (`r data_are_avail_perc`%), even though only `r have_data_avail_statement` articles (`r have_data_avail_statement_perc`%) include a data availability statement. For papers where data was available, `r data_in_supp` papers (`r data_in_supp_perc`%) have data contained in supplementary files published with the paper, `r data_in_table` (`r data_in_table_perc`%) have all the raw data in tables in the text of the paper, and `r data_in_repo` (`r data_in_repo_perc`%) have data in an online repository. The most frequently shared type of data is compositional (e.g. element concentrations, n = `r comp_n`, `r comp_perc`%), followed by radiocarbon and luminescence age data (where the dates are the primary object of analysis, n = `r dates_n`, `r dates_perc`%) and DNA sequences (n = `r dna_n`, `r dna_perc`%). Generally, compositional data is presented in tables in the text, dating data is presented in supplementary files, and DNA data are in repositories (as is typical for DNA data). Data shared in supplementary files and online repositories were most often in Microsoft Excel format (n = `r xlsx_n`, `r xlsx_perc`% of the files in supplements files and repositories), followed by CSV (comma separated variables, a open source plain text spreadsheet format, n = `r csv_n`, `r csv_perc`%), and tables embedded in Microsoft Word or PDF documents (n = `r doc_n`, `r doc_perc`%). When a scripting language such as R, Python, MATLAB or OxCal was used as the analysis software for a paper (n = `r script_n`, `r script_perc`% of the papers where would identify the software), only 2 papers also provided the script with the paper. 


```{r eval=TRUE, fig.cap="No relationship between data file type and data sharing location"}
# correlation of data type and location of sharing
file_type_location <- 
jas_article_survey %>% 
  mutate(file = strsplit(as.character(`What file format?`), ",")) %>% 
  unnest(file) %>% 
  filter(file != "na" & `Where is the data?` != "na") %>% 
  select(file,  `Where is the data?`) %>% 
  mutate(location = case_when(
    grepl("sup", tolower(`Where is the data?`)) ~ "Supplementary",
    grepl("tab", tolower(`Where is the data?`)) ~ "Table",
    grepl("www|dryad|osf", tolower(`Where is the data?`)) ~ "Repository",
  )) %>% 
  mutate(file = case_when(
    grepl("DOCX|doc", file) ~ "DOCX",
    grepl("XLSX| XLSX", file) ~ "XLSX",
    TRUE ~ file
    ))

file_type_location %>% 
  group_by(file, location) %>% 
  tally() %>% 
  ggplot(aes(file, location)) + 
  geom_point(aes(size = n),
             colour = "grey80") +
  theme_bw() + 
  xlab("") + 
  ylab("") +
  scale_size_continuous(range=c(5,25)) + 
  geom_text(aes(label = n)) +
  theme(legend.position = "none") 
```

```{r eval=TRUE, fig.cap="Plot of the relationship between data type and location where it is shared."}
# correlation of data type and location of sharing
data_type_location <- 
jas_article_survey %>% 
  filter(`data type?` != "na" & `Where is the data?` != "na") %>% 
  select(`data type?`, `Where is the data?`) %>% 
  mutate(data_type = case_when(
    grepl("comp", tolower(`data type?`)) ~ "Compositional",
    grepl("c14|osl", tolower(`data type?`)) ~ "Dating",
    grepl("dna", tolower(`data type?`)) ~ "DNA",
    TRUE ~ `data type?`
  )) %>% 
   mutate(location = case_when(
    grepl("sup", tolower(`Where is the data?`)) ~ "Supplementary",
    grepl("tab", tolower(`Where is the data?`)) ~ "Table",
    grepl("www|dryad|osf", tolower(`Where is the data?`)) ~ "Repository"
  )) 

data_type_location %>% 
  group_by(data_type, location) %>% 
  tally() %>% 
  filter(n >= 2) %>% 
  ggplot(aes(data_type, location)) + 
  geom_point(aes(size = n),
             colour = "grey80") +
  theme_bw() + 
  xlab("") + 
  ylab("") +
  scale_size_continuous(range=c(5,25)) + 
  geom_text(aes(label = n)) +
  theme(legend.position = "none") 
```




# Data sets in repositories

<<<<<<< HEAD

```{r demo, eval = TRUE}
# install.packages("rdatacite")

=======
```{r get-citation-data, eval = TRUE}
# install.packages("rdatacite")

# Originat data aquisition on 14 Aug 2017
>>>>>>> 0fd56b87e2615f240e89badc31d17233cb598523
# library(rdatacite)
# dc_arch <- dc_search(q = "archaeology", rows = pretty(100000)[2])

# Saved locally then uploaded to osf.io/tsm89 (too big for GitHub)
# saveRDS(dc_arch, "dc_arch.rds")
# dc_arch <- readRDS("C:\\emacs\\dc_arch.rds")

<<<<<<< HEAD
# library(osfr)
# download_file("tsm89", private = TRUE, path = "../data/raw_data/")
dc_arch <- readRDS("../data/raw_data/dc_arch.rds")
=======
# Download from osf.io with this:
# library(osfr)
# download_file("tsm89", private = TRUE)
dc_arch <- readRDS("../data/raw_data/dc_arch.rds")
```


```{r eval = TRUE}
>>>>>>> 0fd56b87e2615f240e89badc31d17233cb598523

library(tidyverse)
library(stringr)
# glimpse(dc_arch)

dc_arch <- 
dc_arch %>% 
mutate(the_text =  toupper(gsub(" |_|\\(|\\)", "-", rights)),
       the_text = gsub("(\\-)\\1+", "\\1", the_text),
       the_text = gsub("-$", "", the_text)) %>% 
  mutate(cc = case_when(
    grepl("SEMANTICS/OPENACCESS", the_text) ~ "EU Open Access",
    grepl("SEMANTICS/RESTRICTEDACCESS", the_text) ~ "EU Restricted Access",
    grepl("SEMANTICS/CLOSEDACCESS", the_text) ~ "EU Closed Access",
    grepl("CC-BY-[^NC-ND]|CC-BY$|ATTRIBUTION-LICENSE|ATTRIBUTION-[^NON]", the_text) ~ "CC-BY",
    grepl("CC-BY-NC-[^ND]|BY-NC-[^ND]|CC-NC$|ATTRIBUTION-NON-COMMERCIAL-", the_text) ~ "CC-BY-NC",
    grepl("CC-BY-NC-SA-[^ND]|CC-NC-SA$|ATTRIBUTION-NON-COMMERCIAL-SHARE", the_text) ~ "CC-BY-NC-SA",
    grepl("CC-BY-NC-ND|BY-NC-ND|ATTRIBUTION-NONCOMMERCIAL-NO-DERIVATIVE|ATTRIBUTION-NONCOMMERCIAL-NODERIVATIVES|ATTRIBUTION-NONCOMMERCIAL-NODERIVS|NAMENSNENNUNG-NICHTKOMMERZIELL-KEINEBEARBEITUNG|NAMENSNENNUNG-KEINE-KOMMERZIELLE-NUTZUNG", the_text) ~ "CC-BY-NC-ND",
    grepl("ADS|ARCHAEOLOGYDATASERVICE", the_text) ~ "ADS",
    grepl("CC0|CC-0|ZERO", the_text) ~ "CC-0"
  )) %>% 
  mutate(yyyy_created =  as.numeric(substr(created, 1,4)),
         yyyy_date =  as.numeric(substr(date, 1,4)))
```

Our third and final exploration of archaeologist's data sharing behaviours is a 



```{r eval = TRUE}
# select cols of interest
xx <- 
dc_arch %>% 
  select( datacentre,
          allocator ,
          date,
          creator,
          description,
          language,
          contributor,
          rights,
          subject,
          format,
          publisher) 

# tallies
datacentre <-  arrange(as_data_frame(table(xx[ , "datacentre"])), desc(n))
allocator  <-  arrange(as_data_frame(table(xx[ , "allocator"])), desc(n))
dates <-       arrange(as_data_frame(table(xx[ , "date"])), desc(n))
creator <-     arrange(as_data_frame(table(xx[ , "creator"])), desc(n)) 
language <-    arrange(as_data_frame(table(xx[ , "language"])), desc(n))  
contributor <- arrange(as_data_frame(table(xx[ , "contributor"])), desc(n)) 
rights <-      arrange(as_data_frame(table(xx[ , "rights"])), desc(n)) 
publisher  <-  arrange(as_data_frame(table(xx[ , "publisher"])), desc(n)) 
file_format <-  arrange(as_data_frame(table(xx[ , "format"])), desc(n))
```

```{r first-dates}
dates <- 
  dc_arch %>% 
  mutate(yyyy_date = as.numeric(substr(date, 1,4)),
         yyyy_created = as.numeric(substr(created, 1,4)))

# when was the first record created?
first_created <- min(dates$yyyy_created)
first_date <-  min(dates$yyyy_date, na.rm = TRUE)

# when in that big peak
dates_tally <- 
  dates %>% 
  group_by(yyyy_created) %>% 
  tally(sort = TRUE)
```

```{r eval = FALSE}
# text mine a little
library(tidytext)
subject_1gram <- 
xx %>% 
  unnest_tokens(word, subject) %>%
  anti_join(stop_words) %>%
  count(word, sort = TRUE) 

subject_2gram <- 
xx %>% 
  unnest_tokens(bigram, subject, token = "ngrams", n = 2) %>%
  count(word, sort = TRUE) 

subject_3gram <- 
xx %>% 
  unnest_tokens(trigram, subject, token = "ngrams", n = 3) %>%
  count(word, sort = TRUE) 
```

```{r}
# File types

# how many records with file type info?
file_types <- c("pdf|image|imagejpeg|jpg|tiff|png|gif|bmp|ai|illustrator|access|mdb|dbf|dbase|accdb|dbase|doc|rtf|word|arcgis|shape|shp|mapinfo|mid|mif|surfer|xls|excel|csv|spreadsheet|spreadsheet|ply|archeolink|autocad|dwg")

number_of_records_with_file_type <- 
file_format %>% 
  filter(grepl(file_types, tolower(Var1))) %>% 
  summarise(sum = sum(n)) %>% 
  pull(sum)

perc_of_records_with_file_type <- round(number_of_records_with_file_type / nrow(dc_arch) * 100, 0)

# how many that are only PDFs? 
have_a_pdf_in_there <- 
file_format %>% 
   filter(grepl("pdf", tolower(Var1))) %>% 
   mutate(Var1 = tolower(gsub("application/|/", "", Var1)) )

perc_have_a_pdf <- round(sum(have_a_pdf_in_there$n) / number_of_records_with_file_type * 100, 0)

n_only_pdf <-  have_a_pdf_in_there %>% 
    group_by(Var1) %>% 
    tally(sort = TRUE) %>% 
    filter(Var1 %in% c("pdf", "pdf,pdf", "pdfx,pdf", "pdfx")) %>% 
    summarise(nnn = sum(nn)) %>% 
    pull(nnn)

perc_only_pdf <-  round(n_only_pdf / number_of_records_with_file_type * 100, 0)

# how many that are only images?
have_an_image_in_there <-
file_format %>% 
   filter(grepl("image|jpg|tiff|png|gif|bmp|ai|illustrator|imagejpeg", tolower(Var1))) %>% 
   mutate(Var1 = tolower(gsub("application/|/", "", Var1)) )

n_only_image <-  have_an_image_in_there %>% 
    group_by(Var1) %>% 
    tally(sort = TRUE) %>% 
    filter(Var1 %in% c("image", "jpg", "tiff", "png", "gif", "bmp", "ai", "illustrator", "imagejpeg", "imagetiff", "imagepng")) %>% 
    summarise(nnn = sum(nn)) %>% 
    pull(nnn)

perc_only_image <-  round(n_only_image / number_of_records_with_file_type * 100, 0)

# how many records contain a structured data file (csv, xls, dbf, etc)?
have_a_structured_data_file_in_there <- 
  file_format %>% 
  filter(grepl("access|mdb|dbf|dbase|accdb|dbase|arcgis|shape|shp|mapinfo|mid|mif|surfer|xls|excel|csv|spreadsheet|spreadsheet", tolower(Var1))) %>% 
   mutate(Var1 = tolower(gsub("application/|/", "", Var1)) )

n_structured_data_file <- have_a_structured_data_file_in_there %>% 
  group_by(Var1) %>% 
  tally(sort=TRUE) %>% 
  summarise(nnn = sum(nn)) %>% 
  pull(nnn)

perc_structured_data_file <- round(n_structured_data_file / number_of_records_with_file_type * 100, 0)

# count each file type once, even for records with multiple files types
file_format_single <- 
file_format %>% 
  filter(grepl(file_types, tolower(Var1))) %>% 
  mutate(file_format = tolower(gsub("application|/", "", Var1))) %>% 
  mutate(file_format_single = strsplit(as.character(file_format), ",|;")) %>% 
  unnest(file_format_single) 

# how many unique types?
how_many_unique_file_types <- 
file_format_single %>% 
  group_by(file_format_single) %>% 
  tally(sort = TRUE)
  
file_format_simple <- 
file_format_single %>% 
  mutate(file_type = case_when(
    grepl("pdf", file_format_single) ~ "pdf",
    grepl("image|imagejpeg|jpg|tiff|png|gif|bmp|ai|illustrator", file_format_single) ~ "image",
    grepl("access|mdb|dbf|dbase|accdb|dbase", file_format_single) ~ "database",
    grepl("doc|rtf|word", file_format_single) ~ "doc",
    grepl("arcgis|shape|shp|mapinfo|mid|mif|surfer", file_format_single) ~ "GIS",
    grepl("xls|excel|csv|spreadsheet", file_format_single) ~ "spreadsheet",
    grepl("ply", file_format_single) ~ "3D",
    grepl("archeolink", file_format_single) ~ "archeolink",
    grepl("autocad|dwg", file_format_single) ~ "autocad"
  ))  

file_format_simple_tally <- 
file_format_simple %>% 
  filter(!is.na(file_type)) %>% 
  group_by(file_type) %>% 
  tally(sort = TRUE) %>% 
  mutate(perc = round(nn / sum (nn) * 100, 0))

file_format_combos_tally <- 
file_format_simple %>% 
  filter(!is.na(file_type)) %>% 
  group_by(n) %>% 
  filter(n_distinct(file_type) >= 2) %>% 
  slice(1) %>% # look at the file_format col only
  group_by(file_format) %>% 
  tally(sort = TRUE)
```

Our third investigation of archaeologists' data sharing behaviours is an analysis of all records (n = `r prettyNum(nrow(dc_arch), big.mark = ",")`, as of August 2017) of archaeological data files in online repositories tracked by DataCite (an organisation that provides persistent identifiers, or DOIs for research data). The majority of records come from the Archaeology Data Service (ADS) in the UK, followed by the Dutch Archiving and Network Services (DANS-EASY). Although the earliest data dates to `r first_date`, the first records in these repositories were created in `r first_created`

Many of these records are grey literature such as unpublished reports, produced by commercial consultants or research projects. Of  the `r prettyNum(number_of_records_with_file_type,  big.mark = ",")` (`r perc_of_records_with_file_type`%) recrods that include infomation about the file types in the deposit, `r perc_only_pdf`% (n = `r n_only_pdf`) contain only PDFs, followed by `r perc_only_image`% (n = `r prettyNum(n_only_image, big.mark = ",")`) that contain only image files. Structured data files such as spreadsheets, databases and shapefiles are found either alone or together with other file types (typically PDFs) in `r perc_structured_data_file`% (n = `r prettyNum(n_structured_data_file, big.mark = ","`) records.


```{r}
datacentre_plot <- 
  datacentre %>% 
  mutate(Var1 = str_wrap(Var1, 20)) %>% 
  slice(1:10) %>% 
ggplot(aes(reorder(Var1, n),
           n)) +
  geom_col() +
  coord_flip() +
  xlab("Data centre") +
  ylab("") +
  theme_new() +
  theme(axis.text.y  = element_text(size = 8)) 

allocator_plot <- 
ggplot(allocator[1:10,],
       aes(reorder(Var1, n),
           n)) +
  geom_col() +
  coord_flip() +
  theme_new()

creator_plot <- 
ggplot(creator[1:30,],
       aes(reorder(Var1, n),
           n)) +
  geom_col() +
  coord_flip() +
  theme_new()

language_plot <- 
  language %>% 
  mutate(Var2 = ifelse(grepl("en|En", Var1), "en", Var1)) %>% 
  mutate(Var2 = ifelse(grepl("de|ger", Var2), "de", Var2)) %>% 
  group_by(Var2) %>% 
  tally(sort = TRUE) %>% 
  slice(1:5) %>% 
ggplot(aes(reorder(Var2, nn),
           nn)) +
  geom_col() +
  coord_flip()  +
  theme_new() +
  xlab("Language") +
  ylab("")

contributor_plot <- 
ggplot(contributor[1:20,],
       aes(reorder(Var1, n),
           n)) +
  geom_col() +
  coord_flip()  +
  theme_new()


rights_summary <- 
  rights %>% 
  mutate(the_text =  toupper(gsub(" |_|\\(|\\)", "-", Var1)),
         the_text = gsub("(\\-)\\1+", "\\1", the_text),
         the_text = gsub("-$", "", the_text)) %>% 
  mutate(cc = case_when(
    grepl("SEMANTICS/OPENACCESS", the_text) ~ "EU Open Access",
    grepl("SEMANTICS/RESTRICTEDACCESS", the_text) ~ "EU Restricted Access",
    grepl("SEMANTICS/CLOSEDACCESS", the_text) ~ "EU Closed Access",
    grepl("CC-BY-[^NC-ND]|CC-BY$|ATTRIBUTION-LICENSE|ATTRIBUTION-[^NON]", the_text) ~ "CC-BY",
    grepl("CC-BY-NC-[^ND]|BY-NC-[^ND]|CC-NC$|ATTRIBUTION-NON-COMMERCIAL-", the_text) ~ "CC-BY-NC",
    grepl("CC-BY-NC-SA-[^ND]|CC-NC-SA$|ATTRIBUTION-NON-COMMERCIAL-SHARE", the_text) ~ "CC-BY-NC-SA",
    grepl("CC-BY-NC-ND|BY-NC-ND|ATTRIBUTION-NONCOMMERCIAL-NO-DERIVATIVE|ATTRIBUTION-NONCOMMERCIAL-NODERIVATIVES|ATTRIBUTION-NONCOMMERCIAL-NODERIVS|NAMENSNENNUNG-NICHTKOMMERZIELL-KEINEBEARBEITUNG|NAMENSNENNUNG-KEINE-KOMMERZIELLE-NUTZUNG", the_text) ~ "CC-BY-NC-ND",
    grepl("ADS|ARCHAEOLOGYDATASERVICE", the_text) ~ "ADS",
    grepl("CC0|CC-0|ZERO", the_text) ~ "CC-0"
  )) %>% 
  select(cc, n) %>% 
  filter(!is.na(cc)) %>% 
  group_by(cc) %>% 
  tally(sort = TRUE) 
  
rights_plot <- 
ggplot(rights_summary,
       aes(reorder(cc, nn),
           nn)) +
  geom_col() +
  coord_flip()  +
  theme_new() +
  xlab("License") +
  ylab("")


publisher_plot <- 
ggplot(publisher[1:10,],
       aes(reorder(Var1, n),
           n)) +
  geom_col() +
  coord_flip() +
  theme_new()

date_plot <- 
  dates %>% 
  mutate(yyyy = as.numeric(substr(Var1, 1,4))) %>% 
  select(yyyy) %>% 
  ggplot(aes(yyyy)) +
  geom_histogram() +
  theme_new() +
  xlim(c(1950,2017)) +
  xlab("Year") +
  ylab("")

library(plotly)
# ggplotly(date_plot)

format_plot <- 
  
```


```{r dates eval = TRUE}


# why so many in 2010? http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0078080 it's the Dutch

what_2010 <- 
  xx %>% 
  filter(as.numeric(substr(date, 1,4)) == 2010)

why_2013 <- 
  xx %>% 
  filter(as.numeric(substr(date, 1,4)) == 2013) %>% 
  group_by(publisher) %>% 
  tally(sort = TRUE)

why_2012 <- 
  xx %>% 
  filter(as.numeric(substr(date, 1,4)) == 2012) %>% 
  group_by(publisher) %>% 
  tally(sort = TRUE)

why_2011 <- 
  xx %>% 
  filter(as.numeric(substr(date, 1,4)) == 2011) %>% 
  group_by(publisher) %>% 
  tally(sort = TRUE)


why_2010 <- 
xx %>% 
  filter(as.numeric(substr(date, 1,4)) == 2010) %>% 
  group_by(publisher) %>% 
  tally(sort = TRUE)

why_2009 <- 
  xx %>% 
  filter(as.numeric(substr(date, 1,4)) == 2009) %>% 
  group_by(publisher) %>% 
  tally(sort = TRUE)

why_2008 <- 
  xx %>% 
  filter(as.numeric(substr(date, 1,4)) == 2008) %>% 
  group_by(publisher) %>% 
  tally(sort = TRUE)
```
  

```{r eval=TRUE}
# panel of plots
# combine plots for lang and data center
datacentre_and_langugage_plot <- 
  datacentre_plot + annotation_custom(ggplotGrob(language_plot),
                                      xmin = 1.15, 
                                      xmax = 6.15,
                                      ymin = 10000,
                                      ymax = 40000
  )

# combine plots for lisc and year
rights_and_date_plot <- 
  rights_plot + annotation_custom(ggplotGrob(date_plot),
                                      xmin = 1, 
                                      xmax = 5,
                                      ymin = 10000,
                                      ymax = 40000
  )

library(gridExtra)
lay <- rbind(c(1,2),
             c(1,2))
grid.arrange(datacentre_and_langugage_plot,
             rights_and_date_plot,
             # datacentre_plot,
             # allocator_plot,
             # creator_plot,
             # contributor_plot,
             # publisher_plot,
             # rights_plot,
             # language_plot,
             # date_plot,
             layout_matrix = lay)
             
```


```{r}

# look at some relationships
datacentre_rights_table <- 
dc_arch %>% 
  mutate(the_text =  toupper(gsub(" |_|\\(|\\)", "-", rights)),
         the_text = gsub("(\\-)\\1+", "\\1", the_text),
         the_text = gsub("-$", "", the_text)) %>% 
  mutate(cc = case_when(
    grepl("SEMANTICS/OPENACCESS", the_text) ~ "EU Open Access",
    grepl("SEMANTICS/RESTRICTEDACCESS", the_text) ~ "EU Restricted Access",
    grepl("SEMANTICS/CLOSEDACCESS", the_text) ~ "EU Closed Access",
    grepl("CC-BY-[^NC-ND]|CC-BY$|ATTRIBUTION-LICENSE|ATTRIBUTION-[^NON]", the_text) ~ "CC-BY",
    grepl("CC-BY-NC-[^ND]|BY-NC-[^ND]|CC-NC$|ATTRIBUTION-NON-COMMERCIAL-", the_text) ~ "CC-BY-NC",
    grepl("CC-BY-NC-SA-[^ND]|CC-NC-SA$|ATTRIBUTION-NON-COMMERCIAL-SHARE", the_text) ~ "CC-BY-NC-SA",
    grepl("CC-BY-NC-ND|BY-NC-ND|ATTRIBUTION-NONCOMMERCIAL-NO-DERIVATIVE|ATTRIBUTION-NONCOMMERCIAL-NODERIVATIVES|ATTRIBUTION-NONCOMMERCIAL-NODERIVS|NAMENSNENNUNG-NICHTKOMMERZIELL-KEINEBEARBEITUNG|NAMENSNENNUNG-KEINE-KOMMERZIELLE-NUTZUNG", the_text) ~ "CC-BY-NC-ND",
    grepl("ADS|ARCHAEOLOGYDATASERVICE", the_text) ~ "ADS",
    grepl("CC0|CC-0|ZERO", the_text) ~ "CC-0"
  )) %>% 
  group_by(datacentre, cc) %>% 
  filter(!is.na(cc))  %>% 
  tally(sort = TRUE) 

datacentre_rights_table[1:11,] %>% 
  ggplot(aes(cc, datacentre)) + 
  geom_point(aes(size = n),
             colour = "grey80") +
  theme_bw() + 
  xlab("") + 
  ylab("") +
  scale_size_continuous(range=c(5,25)) + 
  geom_text(aes(label = n)) +
  theme(legend.position = "none") 

# changes over time
library(ggrepel)

datacentre_by_year <- 
dc_arch %>% 
  group_by(yyyy_created, datacentre) %>% 
  tally(sort = TRUE) %>% 
  ungroup() %>% 
  filter(n > 150)


  ggplot(datacentre_by_year, 
         aes(yyyy_created,
             n,
             colour = datacentre)) +
  geom_line(size = 2) +
  theme_bw()  +
  scale_y_log10() +
  theme(legend.position = "none")  +
  facet_wrap(~ datacentre)

```

